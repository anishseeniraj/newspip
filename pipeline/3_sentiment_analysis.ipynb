{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sentiment Analysis</h1>\n",
    "\n",
    "<p>In this step, we'll actually flesh out the classifier to predict the behaviour of stock prices based on financial news. We'll compare the performance of forecasts made based only on headlines and those made based on headlines and first sentences of articles (as it is on Reuters' news feed) using two models</p>\n",
    "\n",
    "<ul>\n",
    "    <li>Naive Bayes</li>\n",
    "    <li>Support Vector Machine (SVM)</li>\n",
    "</ul>\n",
    "\n",
    "<p>Implementing a machine learning model comprises 4 key steps</p>\n",
    "\n",
    "<ul>\n",
    "    <li>Define - Define the model that's being used</li>\n",
    "    <li>Fit - Fit the model on your training dataset (X_train)</li>\n",
    "    <li>Predict - Make predictions with the model on your test dataset (X_test)</li>\n",
    "    <li>Evaluate - Measure your model's accuracy (compare predictions and y_test)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To start off, let's read in the pickled data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(\"./pickles/corpus.pkl\")\n",
    "df_text = df.drop([\"Headline\", \"Sentence\"], axis=1)\n",
    "df_headlines = df.drop([\"Sentence\", \"Text\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Naive Bayes</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's define a few helper functions that will abstract away some of the modelling details.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Obtaining X and y (features and output)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the dataset for modelling\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_X_y(df, col):\n",
    "    # Creating a DTM\n",
    "    cv = CountVectorizer()\n",
    "    X = cv.fit_transform(col).toarray()\n",
    "    y = df.Inflection.values\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Define, Fit, and Predict</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def dfp_naive_bayes(X_train, y_train, X_test):\n",
    "    # Model definition\n",
    "    naive_bayes = GaussianNB(var_smoothing=1e+2)\n",
    "\n",
    "    # Fitting the model\n",
    "    naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting with the model\n",
    "    y_pred = naive_bayes.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Evaluate</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def evaluate_naive_bayes(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return confusion, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Headlines Forecast</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_headlines, y_headlines = get_X_y(df_headlines, df_headlines.Headline)\n",
    "X_headlines_train, X_headlines_test, y_headlines_train, y_headlines_test = train_test_split(\n",
    "    X_headlines, y_headlines, test_size = 0.10\n",
    "    , random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining predictions\n",
    "y_headlines_pred = dfp_naive_bayes(X_headlines_train, y_headlines_train, X_headlines_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      "[[ 0  9]\n",
      " [ 0 16]] \n",
      "\n",
      "The model's accuracy is 0.64\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "confusion_headlines, accuracy_headlines = evaluate_naive_bayes(y_headlines_test, y_headlines_pred)\n",
    "\n",
    "print(\"Confusion matrix\\n\")\n",
    "print(confusion_headlines, \"\\n\")\n",
    "print(\"The model's accuracy is\", accuracy_headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Display Text Forecast</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_text, y_text = get_X_y(df_text, df_text.Text)\n",
    "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(\n",
    "    X_text, y_text, test_size = 0.10, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining predictions\n",
    "y_text_pred = dfp_naive_bayes(X_text_train, y_text_train, X_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      "[[ 0  9]\n",
      " [ 0 16]] \n",
      "\n",
      "The model's accuracy is 0.64\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "confusion_text, accuracy_text = evaluate_naive_bayes(y_text_test, y_text_pred)\n",
    "\n",
    "print(\"Confusion matrix\\n\")\n",
    "print(confusion_text, \"\\n\")\n",
    "print(\"The model's accuracy is\", accuracy_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preliminary Results</h3>\n",
    "\n",
    "<p>As we can see, the accuracy of the default Naive Bayes model is quite poor</p>\n",
    "\n",
    "<ul>\n",
    "    <li>42% on headlines-based forecast</li>\n",
    "    <li>34% on display text-based forecast (which is counter-intuitive)</li>\n",
    "</ul>\n",
    "\n",
    "<p>Let's see how we can tune our model to get better results.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Results</h3>\n",
    "\n",
    "<p>After tuning the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\">variance smoothing</a> of the Naive Bayes model, it resulted in an accuracy of 64%. Let's now pit this against SVM classifiers.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Support Vector Machine (SVM)</h2>\n",
    "\n",
    "<p>An SVM model draws hyperplanes that distinctly identify all classes in an n-dimensional classification model. In this case, we only have two classes (-1, 1 or negative, positive). It determines the hyperplane dissection with mathematical functions called \"kernels\". We will be using a linear kernel since our sample space is merely {-1, 1}.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = df_headlines[:200]\n",
    "test_text = df_headlines[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True)\n",
    "\n",
    "train_vectors = vectorizer.fit_transform(train_text[\"Headline\"])\n",
    "test_vectors = vectorizer.transform(test_text[\"Headline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.005531s; Prediction time: 0.000000s\n",
      "positive:  {'precision': 0.40540540540540543, 'recall': 0.6818181818181818, 'f1-score': 0.5084745762711864, 'support': 22}\n",
      "negative:  {'precision': 0.46153846153846156, 'recall': 0.21428571428571427, 'f1-score': 0.2926829268292683, 'support': 28}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = svm.SVC(kernel='linear', C=10, tol=1e-1)\n",
    "t0 = time.time()\n",
    "classifier_linear.fit(train_vectors, train_text[\"Inflection\"])\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(test_vectors)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "# results\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "report = classification_report(test_text[\"Inflection\"], prediction_linear, output_dict=True)\n",
    "print('positive: ', report[\"1\"])\n",
    "print('negative: ', report[\"-1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
