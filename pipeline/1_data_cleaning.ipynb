{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Cleaning</h1>\n",
    "\n",
    "<p>This is the second step of the NLP pipeline. For details on the first step (data collection), look under the \"scrapers\" folder to find the script that scrapes Reuters for company news data based on the stock ticker.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Scraped Data</h2>\n",
    "\n",
    "<p>The data that's been scraped comprises</p>\n",
    "<ul>\n",
    "    <li>Dates</li>\n",
    "    <li>Headlines</li>\n",
    "    <li>First sentences of articles</li>\n",
    "</ul>\n",
    "\n",
    "<p>To start off, let's take a look at the raw dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that although I'm using AAPL here, the Reuters scraper I wrote has been abstracted to scrape data for any ticker\n",
    "original_data = pd.read_csv(\"../dataset/AAPL_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JULY 23, 2020</td>\n",
       "      <td>U.S. Congressional hearing to question tech gi...</td>\n",
       "      <td>A U.S. congressional hearing scheduled for nex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JULY 23, 2020</td>\n",
       "      <td>UPDATE 1-U.S. Congressional hearing to questio...</td>\n",
       "      <td>A U.S. congressional hearing scheduled for nex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JULY 23, 2020</td>\n",
       "      <td>California appeals court rejects Apple TV cons...</td>\n",
       "      <td>A California appeals court has declined a bid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JULY 23, 2020</td>\n",
       "      <td>Apple faces deceptive trade practices probe by...</td>\n",
       "      <td>Multiple U.S. states are investigating Apple I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JULY 23, 2020</td>\n",
       "      <td>Apple faces consumer protection probe by multi...</td>\n",
       "      <td>Multiple U.S. states are investigating Apple I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>APRIL 15, 2019</td>\n",
       "      <td>Huawei says not discussed 5G chipsets with App...</td>\n",
       "      <td>China's Huawei Technologies said on Tuesday it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>APRIL 15, 2019</td>\n",
       "      <td>Apple, allies seek billions in U.S. trial test...</td>\n",
       "      <td>Apple Inc and its allies on Monday will kick o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>APRIL 12, 2019</td>\n",
       "      <td>Apple hit with East Texas patent case over iPh...</td>\n",
       "      <td>A New York-based patent monetization company o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>APRIL 12, 2019</td>\n",
       "      <td>Chinese group to get control of Japan Display ...</td>\n",
       "      <td>A Chinese-Taiwanese group will take control of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>APRIL 12, 2019</td>\n",
       "      <td>Japanese supplier to Apple gets $1.1 bln in ba...</td>\n",
       "      <td>Apple Inc supplier Japan Display Inc said on F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                           Headline  \\\n",
       "0     JULY 23, 2020  U.S. Congressional hearing to question tech gi...   \n",
       "1     JULY 23, 2020  UPDATE 1-U.S. Congressional hearing to questio...   \n",
       "2     JULY 23, 2020  California appeals court rejects Apple TV cons...   \n",
       "3     JULY 23, 2020  Apple faces deceptive trade practices probe by...   \n",
       "4     JULY 23, 2020  Apple faces consumer protection probe by multi...   \n",
       "..              ...                                                ...   \n",
       "678  APRIL 15, 2019  Huawei says not discussed 5G chipsets with App...   \n",
       "679  APRIL 15, 2019  Apple, allies seek billions in U.S. trial test...   \n",
       "680  APRIL 12, 2019  Apple hit with East Texas patent case over iPh...   \n",
       "681  APRIL 12, 2019  Chinese group to get control of Japan Display ...   \n",
       "682  APRIL 12, 2019  Japanese supplier to Apple gets $1.1 bln in ba...   \n",
       "\n",
       "                                              Sentence  \n",
       "0    A U.S. congressional hearing scheduled for nex...  \n",
       "1    A U.S. congressional hearing scheduled for nex...  \n",
       "2    A California appeals court has declined a bid ...  \n",
       "3    Multiple U.S. states are investigating Apple I...  \n",
       "4    Multiple U.S. states are investigating Apple I...  \n",
       "..                                                 ...  \n",
       "678  China's Huawei Technologies said on Tuesday it...  \n",
       "679  Apple Inc and its allies on Monday will kick o...  \n",
       "680  A New York-based patent monetization company o...  \n",
       "681  A Chinese-Taiwanese group will take control of...  \n",
       "682  Apple Inc supplier Japan Display Inc said on F...  \n",
       "\n",
       "[683 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Null values</h2>\n",
    "\n",
    "<p>A common issue in the date cleaning process is dealing with null values. Let's see how our original dataset fares in this aspect.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        False\n",
       "Headline    False\n",
       "Sentence    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As we can see, there aren't any null values in the original dataset which is an indicator that our scraper performed relatively well. But then again, null values are a common issue only when dealing with numeric data, so soon enough, we will have to apply text pre-processing techniques to this dataset.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Date Format</h2>\n",
    "\n",
    "<p>Let's convert the \"Date\" column into a pandas Timestamp (pandas equivalent of the datetime object) and take a look at the results.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>U.S. Congressional hearing to question tech gi...</td>\n",
       "      <td>A U.S. congressional hearing scheduled for nex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>UPDATE 1-U.S. Congressional hearing to questio...</td>\n",
       "      <td>A U.S. congressional hearing scheduled for nex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>California appeals court rejects Apple TV cons...</td>\n",
       "      <td>A California appeals court has declined a bid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>Apple faces deceptive trade practices probe by...</td>\n",
       "      <td>Multiple U.S. states are investigating Apple I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>Apple faces consumer protection probe by multi...</td>\n",
       "      <td>Multiple U.S. states are investigating Apple I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                           Headline  \\\n",
       "0 2020-07-23  U.S. Congressional hearing to question tech gi...   \n",
       "1 2020-07-23  UPDATE 1-U.S. Congressional hearing to questio...   \n",
       "2 2020-07-23  California appeals court rejects Apple TV cons...   \n",
       "3 2020-07-23  Apple faces deceptive trade practices probe by...   \n",
       "4 2020-07-23  Apple faces consumer protection probe by multi...   \n",
       "\n",
       "                                            Sentence  \n",
       "0  A U.S. congressional hearing scheduled for nex...  \n",
       "1  A U.S. congressional hearing scheduled for nex...  \n",
       "2  A California appeals court has declined a bid ...  \n",
       "3  Multiple U.S. states are investigating Apple I...  \n",
       "4  Multiple U.S. states are investigating Apple I...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = original_data.copy() # making a copy of the original DataFrame to work with\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>That's pretty much everything we have to do to the \"Date\" column as far as cleaning it up is concerned.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Common Functions to Clean Text Data</h2>\n",
    "\n",
    "<p>There are several ways to clean/process text data before feeding it into a model. The exact functions required varies across different use cases. Here are some of the procecssing steps we need to employ for this project</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Converting to lowercase</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>For the next set of cleanup functions, we are going to have to make a few imports</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Getting rid of punctuation</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return re.sub(\"[%s]\" % re.escape(string.punctuation), \"\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Replacing special characters</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_special_chars(text):\n",
    "    text = text.replace(\"Ã¢â‚¬â„¢\", \"\\'\")\n",
    "    text = text.replace(\"ÃƒÂ¤ÃƒÅ¸\", \"\")\n",
    "    text = text.replace(\"ÃƒÂ¼\", \"\")\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Replacing country names (abbreviations)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_country_names(text):\n",
    "    text = text.replace(\"U.S\", \"United States\")\n",
    "    text = text.replace(\"EU\", \"Europe\")\n",
    "    text = text.replace(\"UK\", \"United Kingdom\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Removing numbers from words (034220.KS, COVID-19 to COVID etc.)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "    return re.sub(\"[\\d-]\", \"\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Removing stop words</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens_no_stop_words = [word for word in text_tokens if not word in stopwords.words()]\n",
    "    text = \" \".join(tokens_no_stop_words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This is a good start. As we progress, if we notice unexpected results, we can come back and process the text in a couple more ways by implementing </p>\n",
    "    <ul>\n",
    "        <li>Lemmatization - Dealing with word inflections (ex. \"take\" is the same as \"taken\" or \"took\")</li>\n",
    "        <li>Creating n-grams - Considering n words at a time (ex. a bi-gram would be \"United States\" as opposed to considering \"united\" and \"states\" separately)</li>\n",
    "        <li>Parts of speech tagging - Recognizing nouns, pronouns (ex. \"Canada\", \"he\", \"it\" etc.)</li>\n",
    "        <li>Removal of meaningless text</li>\n",
    "        <li>Removal of stop words - done after discovering the corpus had poor content while doing EDA</li>\n",
    "        <li>Word embedding - synonyms</li>\n",
    "    </ul>\n",
    "\n",
    "<p>For now, let's clean up the text in our dataset using the utility functions defined above.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cleaning the Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies all the cleanup functions to a piece of text\n",
    "def clean_up_text(text):\n",
    "    text = replace_country_names(text)\n",
    "    text = replace_special_chars(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = to_lower(text)\n",
    "    text = remove_stop_words(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "clean = lambda text: clean_up_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame with clean text\n",
    "headline_clean = pd.DataFrame(df[\"Headline\"].apply(clean))\n",
    "sentence_clean = pd.DataFrame(df[\"Sentence\"].apply(clean))\n",
    "df_clean = pd.concat([headline_clean, sentence_clean], axis=1)\n",
    "df_clean = pd.concat([df[\"Date\"], df_clean], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Display Text</h2>\n",
    "\n",
    "<p>Let's make a new feature, \"Text\", that combines the headline and first sentence for each article. This makes sense as somebody perusing through Reuters will see the headline and first sentence for every article in the listing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the \"Text\" feature that combines headlines and first sentences\n",
    "df_clean[\"Headline\"] = df_clean[\"Headline\"] + \" \" # space after last word in headline\n",
    "df_clean[\"Text\"] = df_clean[\"Headline\"] + df_clean[\"Sentence\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Stock Price</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>If you inspect element on the Yahoo Finance page that contains historical stock data (past 5y years), you can find the URL to the dataset that contains the past 5y stock price. To retrieve the data, I'll be using a utility function that I wrote for <a href=\"https://github.com/anishseeniraj/stockastic\">Stockastic</a>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../assets/img/yahoo_finance_5y_url.png\" alt=\"Yahoo Finance stock data URL\" width=777 height=777>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "def read_historic_data(ticker):\n",
    "    \"\"\"\n",
    "    Reads in historic (past 5y) stock data from Yahoo Finance and returns\n",
    "    a pandas DataFrame containing the data\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculating today's date and the date 5y ago\n",
    "    date_today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "    dtc = date_today.split(\"-\")\n",
    "    date_five_years_ago = (\n",
    "        datetime.today() - relativedelta(years=5)).strftime(\"%Y-%m-%d\")\n",
    "    dfyc = date_five_years_ago.split(\"-\")\n",
    "\n",
    "    # Calculates Unix timestamps for start and end dates to fetch data\n",
    "    timestamp_today = int(datetime(int(dtc[0]), int(dtc[1]), int(\n",
    "        dtc[2]), 0, 0).replace(tzinfo=timezone.utc).timestamp())\n",
    "    timestamp_five_years_ago = int((datetime(int(dfyc[0]), int(dfyc[1]), int(\n",
    "        dfyc[2]), 0, 0)).replace(tzinfo=timezone.utc).timestamp())\n",
    "\n",
    "    # Reading in stock data from Yahoo Finance in the above timestamps' range\n",
    "    csv_url = \"https://query1.finance.yahoo.com/v7/finance/download/\" + ticker + \\\n",
    "        \"?period1=\" + str(timestamp_five_years_ago) + \"&period2=\" + \\\n",
    "        str(timestamp_today) + \"&interval=1d&events=history\"\n",
    "    df = pd.read_csv(csv_url)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_price = read_historic_data(\"AAPL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's take a look at the stock price dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-03</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>122.570000</td>\n",
       "      <td>117.519997</td>\n",
       "      <td>118.440002</td>\n",
       "      <td>109.155342</td>\n",
       "      <td>69976000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-08-04</td>\n",
       "      <td>117.419998</td>\n",
       "      <td>117.699997</td>\n",
       "      <td>113.250000</td>\n",
       "      <td>114.639999</td>\n",
       "      <td>105.653229</td>\n",
       "      <td>124138600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-08-05</td>\n",
       "      <td>112.949997</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>112.099998</td>\n",
       "      <td>115.400002</td>\n",
       "      <td>106.353653</td>\n",
       "      <td>99312600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-06</td>\n",
       "      <td>115.970001</td>\n",
       "      <td>116.500000</td>\n",
       "      <td>114.120003</td>\n",
       "      <td>115.129997</td>\n",
       "      <td>106.585083</td>\n",
       "      <td>52903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-08-07</td>\n",
       "      <td>114.580002</td>\n",
       "      <td>116.250000</td>\n",
       "      <td>114.500000</td>\n",
       "      <td>115.519997</td>\n",
       "      <td>106.946136</td>\n",
       "      <td>38670400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  2015-08-03  121.500000  122.570000  117.519997  118.440002  109.155342   \n",
       "1  2015-08-04  117.419998  117.699997  113.250000  114.639999  105.653229   \n",
       "2  2015-08-05  112.949997  117.440002  112.099998  115.400002  106.353653   \n",
       "3  2015-08-06  115.970001  116.500000  114.120003  115.129997  106.585083   \n",
       "4  2015-08-07  114.580002  116.250000  114.500000  115.519997  106.946136   \n",
       "\n",
       "      Volume  \n",
       "0   69976000  \n",
       "1  124138600  \n",
       "2   99312600  \n",
       "3   52903000  \n",
       "4   38670400  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historic_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         datetime64[ns]\n",
       "Open                float64\n",
       "High                float64\n",
       "Low                 float64\n",
       "Close               float64\n",
       "Adj Close           float64\n",
       "Volume                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing the date format\n",
    "historic_price[\"Date\"] = pd.to_datetime(historic_price.Date)\n",
    "\n",
    "historic_price.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-03</td>\n",
       "      <td>118.440002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-08-04</td>\n",
       "      <td>114.639999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-08-05</td>\n",
       "      <td>115.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-06</td>\n",
       "      <td>115.129997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-08-07</td>\n",
       "      <td>115.519997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       Close\n",
       "0 2015-08-03  118.440002\n",
       "1 2015-08-04  114.639999\n",
       "2 2015-08-05  115.400002\n",
       "3 2015-08-06  115.129997\n",
       "4 2015-08-07  115.519997"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Working with the close prices only\n",
    "historic_price = historic_price[[\"Date\", \"Close\"]].copy()\n",
    "\n",
    "historic_price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's add a column to the historic price DataFrame indicating whether there was a rise/fall in the stock price in comparison to the previous day. We'll call this feature the <i>inflection</i> of the stock.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic_price[\"Inflection\"] = 0\n",
    "\n",
    "for i in range(0, len(historic_price)):\n",
    "    if(i == 0):\n",
    "        historic_price[\"Inflection\"][i] = 0\n",
    "    elif(historic_price[\"Close\"][i] >= historic_price[\"Close\"][i - 1]):\n",
    "        historic_price[\"Inflection\"][i] = 1\n",
    "    else:\n",
    "        historic_price[\"Inflection\"][i] = -1\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Inflection</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-08-03</th>\n",
       "      <td>118.440002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-04</th>\n",
       "      <td>114.639999</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-05</th>\n",
       "      <td>115.400002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-06</th>\n",
       "      <td>115.129997</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-07</th>\n",
       "      <td>115.519997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Close  Inflection\n",
       "Date                              \n",
       "2015-08-03  118.440002           0\n",
       "2015-08-04  114.639999          -1\n",
       "2015-08-05  115.400002           1\n",
       "2015-08-06  115.129997          -1\n",
       "2015-08-07  115.519997           1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting Date as the index\n",
    "historic_price.set_index(\"Date\", inplace=True)\n",
    "historic_price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now that we've got a feature that indicates whether the stock price went up or down, we can combine this data with the news dataset to move along in our NLP pipeline.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Adding Stock Price Inflection</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We have to keep in mind that there is the possibility of news articles being released when the market is closed. In this case, I've decided to use the same inflection value as the most recently assigned inflection value.<p>\n",
    "<p>(<i>Note that this can be dealt with in many ways, but since our sample space is only {-1, 1}, I'm going to stick with using the previous valid inflection value to avoid complications.</i>)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of news articles released when the market was closed - 44\n"
     ]
    }
   ],
   "source": [
    "# Setting df_clean's inflection in correspondence with the historic inflection\n",
    "df_clean[\"Inflection\"] = 0\n",
    "market_close = 0 # keeps track of the number of articles released during market close\n",
    "\n",
    "for i in range(0, len(df_clean)):\n",
    "    try:\n",
    "        df_clean[\"Inflection\"][i] = historic_price.loc[df_clean[\"Date\"][i]].Inflection\n",
    "    except:\n",
    "        market_close += 1\n",
    "        df_clean[\"Inflection\"][i] = df_clean[\"Inflection\"][i - 1]\n",
    "\n",
    "print(\"Number of news articles released when the market was closed -\", market_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Text</th>\n",
       "      <th>Inflection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>united states congressional hearing question t...</td>\n",
       "      <td>united states congressional hearing scheduled ...</td>\n",
       "      <td>united states congressional hearing question t...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>update united states congressional hearing que...</td>\n",
       "      <td>united states congressional hearing scheduled ...</td>\n",
       "      <td>update united states congressional hearing que...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>california appeals court rejects apple tv cons...</td>\n",
       "      <td>california appeals court declined bid consumer...</td>\n",
       "      <td>california appeals court rejects apple tv cons...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>apple faces deceptive trade practices probe mu...</td>\n",
       "      <td>multiple united states states investigating ap...</td>\n",
       "      <td>apple faces deceptive trade practices probe mu...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>apple faces consumer protection probe multiple...</td>\n",
       "      <td>multiple united states states investigating ap...</td>\n",
       "      <td>apple faces consumer protection probe multiple...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                           Headline  \\\n",
       "0 2020-07-23  united states congressional hearing question t...   \n",
       "1 2020-07-23  update united states congressional hearing que...   \n",
       "2 2020-07-23  california appeals court rejects apple tv cons...   \n",
       "3 2020-07-23  apple faces deceptive trade practices probe mu...   \n",
       "4 2020-07-23  apple faces consumer protection probe multiple...   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0  united states congressional hearing scheduled ...   \n",
       "1  united states congressional hearing scheduled ...   \n",
       "2  california appeals court declined bid consumer...   \n",
       "3  multiple united states states investigating ap...   \n",
       "4  multiple united states states investigating ap...   \n",
       "\n",
       "                                                Text  Inflection  \n",
       "0  united states congressional hearing question t...          -1  \n",
       "1  update united states congressional hearing que...          -1  \n",
       "2  california appeals court rejects apple tv cons...          -1  \n",
       "3  apple faces deceptive trade practices probe mu...          -1  \n",
       "4  apple faces consumer protection probe multiple...          -1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Duplicates</h2>\n",
    "\n",
    "<p>We should retain only one entry in the dataset for a given day as opposed to having multiple entries. So we'll keep the most recent article for that day and remove the rest.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Text</th>\n",
       "      <th>Inflection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>united states congressional hearing question t...</td>\n",
       "      <td>united states congressional hearing scheduled ...</td>\n",
       "      <td>united states congressional hearing question t...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>nvidia expresses interest softbanks chip compa...</td>\n",
       "      <td>softbank group corps chip company arm holdings...</td>\n",
       "      <td>nvidia expresses interest softbanks chip compa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>gilstrap denies apple bid delay jury trial due...</td>\n",
       "      <td>united states district judge rodney gilstrap m...</td>\n",
       "      <td>gilstrap denies apple bid delay jury trial due...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>apple settles east texas patent case drops las...</td>\n",
       "      <td>apple inc agreed settle lawsuit accusing infri...</td>\n",
       "      <td>apple settles east texas patent case drops las...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>apple says full return offices year bloomberg ...</td>\n",
       "      <td>apple inc aaplo told staff full return united ...</td>\n",
       "      <td>apple says full return offices year bloomberg ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                           Headline  \\\n",
       "0 2020-07-23  united states congressional hearing question t...   \n",
       "1 2020-07-22  nvidia expresses interest softbanks chip compa...   \n",
       "2 2020-07-21  gilstrap denies apple bid delay jury trial due...   \n",
       "3 2020-07-15  apple settles east texas patent case drops las...   \n",
       "4 2020-07-13  apple says full return offices year bloomberg ...   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0  united states congressional hearing scheduled ...   \n",
       "1  softbank group corps chip company arm holdings...   \n",
       "2  united states district judge rodney gilstrap m...   \n",
       "3  apple inc agreed settle lawsuit accusing infri...   \n",
       "4  apple inc aaplo told staff full return united ...   \n",
       "\n",
       "                                                Text  Inflection  \n",
       "0  united states congressional hearing question t...          -1  \n",
       "1  nvidia expresses interest softbanks chip compa...           1  \n",
       "2  gilstrap denies apple bid delay jury trial due...          -1  \n",
       "3  apple settles east texas patent case drops las...           1  \n",
       "4  apple says full return offices year bloomberg ...          -1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.drop_duplicates(subset=[\"Date\"], inplace=True)\n",
    "df_clean.reset_index(drop=True, inplace=True)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exporting Data</h2>\n",
    "\n",
    "<p>Now that we've cleaned the dataset a bit, we're almost ready to export it for further use. The two formats that we'll be exporting the data in are<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Corpus - Collection of text (what we currently have in df_clean)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_pickle(\"./pickles/corpus.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Document-Term Matrix (DTM) - Bag of words (matrix-like structure to keep track of word count)</li>\n",
    "\n",
    "<p><i>With this method, we'll also be getting rid of stop words (words that add little to no meaning to text).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Removing stop words\n",
    "cv_headline = CountVectorizer(stop_words=\"english\")\n",
    "cv_sentence = CountVectorizer(stop_words=\"english\")\n",
    "cv_text = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Fitting the DTM transformer\n",
    "headline_cv = cv_headline.fit_transform(df_clean.Headline)\n",
    "sentence_cv = cv_sentence.fit_transform(df_clean.Sentence)\n",
    "text_cv = cv_text.fit_transform(df_clean.Text)\n",
    "\n",
    "# Creating the DTM\n",
    "headline_dtm = pd.DataFrame(headline_cv.toarray(), columns=cv_headline.get_feature_names())\n",
    "sentence_dtm = pd.DataFrame(sentence_cv.toarray(), columns=cv_sentence.get_feature_names())\n",
    "text_dtm = pd.DataFrame(text_cv.toarray(), columns=cv_text.get_feature_names())\n",
    "\n",
    "# Re-indexing to dates\n",
    "headline_dtm.index = df_clean.Date\n",
    "sentence_dtm.index = df_clean.Date\n",
    "text_dtm.index = df_clean.Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's pickle the DTMs (headlines, sentences, and display text separately).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_dtm.to_pickle(\"./pickles/headline_dtm.pkl\")\n",
    "sentence_dtm.to_pickle(\"./pickles/sentence_dtm.pkl\")\n",
    "text_dtm.to_pickle(\"./pickles/text_dtm.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
