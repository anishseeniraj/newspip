{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sentiment Analysis</h1>\n",
    "\n",
    "<p>In this step, we'll actually flesh out the classifier to predict the behaviour of stock prices based on financial news. We'll compare the performance of forecasts made based only on headlines and those made based on headlines and first sentences of articles (as it is on Reuters' news feed) using a Naive Bayes model.</p>\n",
    "\n",
    "<p>Implementing a machine learning model comprises 4 key steps</p>\n",
    "\n",
    "<ul>\n",
    "    <li>Define - Define the model that's being used</li>\n",
    "    <li>Fit - Fit the model on your training dataset (X_train)</li>\n",
    "    <li>Predict - Make predictions with the model on your test dataset (X_test)</li>\n",
    "    <li>Evaluate - Measure your model's accuracy (compare predictions and y_test)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To start off, let's read in the pickled data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(\"./pickles/corpus.pkl\")\n",
    "df_text = df.drop([\"Headline\", \"Sentence\"], axis=1)\n",
    "df_headlines = df.drop([\"Sentence\", \"Text\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Naive Bayes</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's define a few helper functions that will abstract away some of the modelling details.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Obtaining X and y (features and output)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the dataset for modelling\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_X_y(df, col):\n",
    "    # Creating a DTM\n",
    "    cv = CountVectorizer()\n",
    "    X = cv.fit_transform(col).toarray()\n",
    "    y = df.Inflection.values\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Define, Fit, and Predict</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def dfp_naive_bayes(X_train, y_train, X_test):\n",
    "    # Model definition\n",
    "    naive_bayes = GaussianNB(var_smoothing=1e-2)\n",
    "\n",
    "    # Fitting the model\n",
    "    naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting with the model\n",
    "    y_pred = naive_bayes.predict(X_test)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Evaluate</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def evaluate_naive_bayes(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return confusion, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Headlines Forecast</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_headlines, y_headlines = get_X_y(df_headlines, df_headlines.Headline)\n",
    "X_headlines_train, X_headlines_test, y_headlines_train, y_headlines_test = train_test_split(\n",
    "    X_headlines, y_headlines, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining predictions\n",
    "y_headlines_pred = dfp_naive_bayes(X_headlines_train, y_headlines_train, X_headlines_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      "[[12 11]\n",
      " [18  9]] \n",
      "\n",
      "The model's accuracy is 0.42\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "confusion_headlines, accuracy_headlines = evaluate_naive_bayes(y_headlines_test, y_headlines_pred)\n",
    "\n",
    "print(\"Confusion matrix\\n\")\n",
    "print(confusion_headlines, \"\\n\")\n",
    "print(\"The model's accuracy is\", accuracy_headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Display Text Forecast</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_text, y_text = get_X_y(df_text, df_text.Text)\n",
    "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(\n",
    "    X_text, y_text, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining predictions\n",
    "y_text_pred = dfp_naive_bayes(X_text_train, y_text_train, X_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      "[[ 7 16]\n",
      " [17 10]] \n",
      "\n",
      "The model's accuracy is 0.34\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "confusion_text, accuracy_text = evaluate_naive_bayes(y_text_test, y_text_pred)\n",
    "\n",
    "print(\"Confusion matrix\\n\")\n",
    "print(confusion_text, \"\\n\")\n",
    "print(\"The model's accuracy is\", accuracy_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preliminary Results</h3>\n",
    "\n",
    "<p>As we can see, the accuracy of the default Naive Bayes model is quite poor</p>\n",
    "\n",
    "<ul>\n",
    "    <li>42% on headlines-based forecast</li>\n",
    "    <li>34% on display text-based forecast (which is counter-intuitive)</li>\n",
    "</ul>\n",
    "\n",
    "<p>Let's see how we can tune our model to get better results.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
